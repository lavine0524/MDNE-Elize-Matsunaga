{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f9b583",
   "metadata": {},
   "source": [
    "### 1. Inteligência Artificial (Modelo)\n",
    "\n",
    "* **Antes:** Usava apenas `spacy.load(\"pt_core_news_sm\")` (versão leve/burra).\n",
    "* **Depois:** Implementamos um bloco `try/except` que prioriza o modelo **`pt_core_news_lg`** (Large/Inteligente), mas mantém o `sm` como backup de segurança caso o download falhe.\n",
    "\n",
    "### 2. Correção de Erros (Pipeline Customizado)\n",
    "\n",
    "* **Antes:** Confiava 100% na IA, o que gerava erros (Elize = Empresa, Acho = Pessoa).\n",
    "* **Depois:** Adicionamos um **`Entity Ruler`** (Régua de Entidades) **antes** do reconhecimento automático. Isso nos permitiu:\n",
    "* Criar um \"Gabarito\" (Forçar Elize -> Pessoa).\n",
    "* Criar uma \"Lista Negra\" (Ignorar verbos como \"Vi\" e \"Acho\").\n",
    "\n",
    "\n",
    "### 3. Engenharia de Dados (Limpeza)\n",
    "\n",
    "* **Antes:** Apagava menções e hashtags inteiras (`@usuario`, `#tema`).\n",
    "* **Depois:** Removemos apenas os símbolos (`@` e `#`), preservando o texto útil (ex: `justiça_br`, `truecrimebr`) para enriquecer a análise de entidades e sentimentos.\n",
    "* **Performance:** Movemos as Expressões Regulares (`re`) para fora da função, usando **`re.compile()`**. Isso carrega as regras na memória uma única vez, tornando o código muito mais rápido.\n",
    "\n",
    "### 4. Visualização\n",
    "\n",
    "* **Antes:** Mostrava todas as entidades encontradas, inclusive os erros.\n",
    "* **Depois:** Criamos um filtro (`if ent.label_ == \"IGNORAR\": continue`) para limpar a saída do terminal, escondendo os \"falsos positivos\" que mapeamos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
