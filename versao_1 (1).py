# =========================================================
# PROJETO: Modelagem de Dados N√£o Estruturados - Etapa 1
# TEMA: An√°lise do Caso Elize Matsunaga
#
# INTEGRANTES DO GRUPO:
# 1. Bianca Lavine
# 2. Let√≠cia Braz
# 3. Kaio Vitor
#
# PROFESSORA: Adriana Carla Damasceno
# =========================================================

import re
import spacy
from spacy.language import Language


# 1. PR√â-COMPILA√á√ÉO DE REGEX (OTIMIZA√á√ÉO DE PERFORMANCE)
# Compilamos os padr√µes aqui para n√£o recri√°-los a cada frase (muito mais r√°pido)
RE_URL = re.compile(r'https?://\S+|www\.\S+')
# Risadas: kkk, rsrs, hahaha, huahua (independente de mai√∫sculas)
RE_RISADAS = re.compile(r'(?i)\b(k+|r+|s+|(rs)+|(ha)+|(hua)+)\b')
# Pontua√ß√£o repetida: "!!!!" vira "!"
RE_PONTUACAO = re.compile(r'([!?,.])\1+')
# Espa√ßos m√∫ltiplos
RE_ESPACOS = re.compile(r'\s+')


# 2. CARREGAMENTO DO MODELO SPACY
print("Carregando modelo de linguagem... (Aguarde)")

try:
    # Prioridade: Modelo Large (Mais inteligente)
    nlp = spacy.load("pt_core_news_lg")
except OSError:
    print("‚ö†Ô∏è  AVISO: Modelo 'pt_core_news_lg' n√£o encontrado.")
    print("   Tentando carregar o modelo 'sm' (backup)...")
    try:
        nlp = spacy.load("pt_core_news_sm")
    except:
        print("‚ùå ERRO CR√çTICO: Nenhum modelo spaCy encontrado.")
        print("   Execute no terminal: python -m spacy download pt_core_news_lg")
        exit()


# 3. PERSONALIZA√á√ÉO (ENTITY RULER)
# Regras manuais para corrigir falhas de interpreta√ß√£o em textos curtos
if not nlp.has_pipe("entity_ruler"):
    ruler = nlp.add_pipe("entity_ruler", before="ner")

    padroes = [
        # --- GABARITO (O que deve ser identificado) ---
        {"label": "PER", "pattern": "Elize Matsunaga"},
        {"label": "PER", "pattern": "Elize"},
        {"label": "LOC", "pattern": "Trememb√©"},
        {"label": "ORG", "pattern": "Netflix"},
        {"label": "ORG", "pattern": "Uber"},
        {"label": "MISC", "pattern": "True Crime"},
        {"label": "ORG", "pattern": "justi√ßa_br"},  # Perfil sem o @

        # --- FILTRO (O que deve ser ignorado) ---
        # Palavras comuns que o modelo confunde com nomes pr√≥prios
        {"label": "IGNORAR", "pattern": "Vi"},
        {"label": "IGNORAR", "pattern": "Acho"},
        {"label": "IGNORAR", "pattern": "Gente"},
        {"label": "IGNORAR", "pattern": "Olha"},
    ]
    ruler.add_patterns(padroes)


# 4. FUN√á√ïES DE LIMPEZA E AN√ÅLISE
def limpar_texto(texto_bruto):
    """
    Limpa o texto preservando Emojis (sentimento) e palavras-chave de Hashtags/Men√ß√µes.
    Usa regex compilado para alta performance.
    """
    # 1. Remove URLs (Links n√£o t√™m sentimento)
    texto = RE_URL.sub('', texto_bruto)

    # 2. Limpeza de Men√ß√µes (@) e Hashtags (#)
    # Removemos apenas os s√≠mbolos, mantendo o texto (Ex: #justi√ßa -> justi√ßa)
    # Isso enriquece a an√°lise de sentimento posterior
    texto = texto.replace('@', '').replace('#', '')

    # 3. Remove risadas (ru√≠do)
    texto = RE_RISADAS.sub('', texto)

    # 4. Normaliza pontua√ß√£o (Ex: "Crime!!!!" -> "Crime!")
    texto = RE_PONTUACAO.sub(r'\1', texto)

    # 5. Remove espa√ßos extras e quebras de linha
    texto = RE_ESPACOS.sub(' ', texto).strip()

    return texto


def analisar_comentario(comentario_original):
    # Passo A: Limpeza Otimizada
    texto_limpo = limpar_texto(comentario_original)

    # Passo B: Processamento NLP
    doc = nlp(texto_limpo)

    # Exibi√ß√£o dos Resultados
    print(f"\n{'='*60}")
    print(f"üìù ORIGINAL: {comentario_original}")
    print(f"üßπ LIMPO:    {texto_limpo}")
    print(f"{'-'*60}")
    print("üîç ENTIDADES DETECTADAS:")

    encontrou_algo = False
    for ent in doc.ents:
        # Pula entidades marcadas na lista negra
        if ent.label_ == "IGNORAR":
            continue

        encontrou_algo = True
        print(f"   ‚Ä¢ {ent.text:<20} | Tipo: {ent.label_}")

    if not encontrou_algo:
        print("   (Nenhuma entidade relevante encontrada)")
    print(f"{'='*60}")



if __name__ == "__main__":
    print("\n:. INICIANDO AN√ÅLISE DE ENTIDADES - PROJETO ELIZE (FINAL) .:\n")

    # Lista de coment√°rios simulados (Futuramente vir√° da API do Reddit)
    comentarios_reddit = [
        "A Elize Matsunaga agora √© motorista de app? üò± Vi no link https://reddit.com/r/crime kkkkkk #elizematsunaga",
        "Acho um absurdo ela ter sa√≠do de Trememb√© t√£o cedo... @justi√ßa_br fiquem de olho!",
        "O document√°rio da Netflix sobre a Elize √© muito bom, mostra detalhes do crime em SP. rsrsrsrs",
        "Gente, n√£o d√° pra acreditar que ela est√° solta. #justi√ßa #truecrimebr kkkk",
        "A empresa Uber deveria banir motoristas com antecedentes criminais graves!!!!!"
    ]

    # Processamento iterativo
    for comentario in comentarios_reddit:
        analisar_comentario(comentario)


